{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaYoy3cMTOOD"
   },
   "source": [
    "# Q -2 Non-causal Transformer based encoder-decoder model using embedding layer and relative positions with position encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d-vuskL4ahx"
   },
   "source": [
    "| **Model**                                     | **Tasks and Comments**                                                                                                                                                                                | **Status**        | **Individual Responsible** |\n",
    "|-----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------|----------------------------|\n",
    "| **Non-causal Transformer-based encoder-decoder model using embedding layer and relative positions with position encodings** |                                                                                                                                                                                                      |                   |                            |\n",
    "| **Preprocessing Steps**                       | 1. Lowercasing all text for uniformity. <br> 2. Contraction expansion (e.g., \"can't\" → \"cannot\", \"I'm\" → \"I am\"). <br> 3. Replacing slang terms (e.g., \"u\" → \"you\", \"brb\" → \"be right back\"). <br> 4. Removing special characters to retain only alphanumeric text. <br> 5. Lemmatizing words to their base forms (e.g., \"running\" → \"run\"). <br> 6. Tokenizing text into individual words. <br> 7. Padding/truncating sequences to a fixed length (`MAX_LEN`). <br> 8. Adding `<start>` and `<end>` tokens to define sentence boundaries. <br> 9. Splitting data into an 80-20 train-test split. <br> 10. Handling out-of-vocabulary (OOV) words with `<unk>` token. | **Done**          | Dharmil Patel             |\n",
    "| Training                                      | Model built and trained with early stopping; handled training and validation correctly.                                                                                                               | **Done**          | Dharmil Patel             |\n",
    "| Evaluation                                    | ROUGE-L Score and BERT Score computed using test samples.                                                                                                                                            | **Done**          | Dharmil Patel             |\n",
    "| Interpretation                                | Using LIME for token-level explanations of predictions.                                                                                                                                              | **Done**          | Dharmil Patel             |\n",
    "| AUC Score                                     | Macro AUC score computed for test data; next step: Test on larger dataset and interpretability.                                                                                                       | **Done**          | Dharmil Patel             |\n",
    "| 1st Round of Tuning                           | Issue: Adjusted `batch_size` and `max_len` for better memory usage.                                                                                                                                  | **Pending**       | Atif Ahmed                |\n",
    "| 2nd Round of Tuning                           | Issue: Fine-tuned learning rate and embedding dimensions for better performance.                                                                                                                     | **Pending**       | Atif Ahmed                |\n",
    "| Deployment                                    | Model successfully deployed with inference pipeline for predictions.                                                                                                                                 | **Done**          | Atif Ahmed                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6er0Yxo2mZ38",
    "outputId": "f6db78d3-08cc-4745-82c1-a673328f3617"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM, LayerNormalization, MultiHeadAttention, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lBUkKmWnQ8q",
    "outputId": "3d9af912-ed2e-456e-cf71-c0e179036a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   human   2000 non-null   object\n",
      " 1   gpt     2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '/content/final_chat.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path,nrows=2000)\n",
    "\n",
    "\n",
    "# Display dataset information and first few rows\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Eu21cKuCnRCE",
    "outputId": "4307ade6-a89c-4468-e761-c3837025db27"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"human\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"*deep breath* I can already feel some tension releasing.\",\n          \"I\\\"m afraid, therapist. Afraid that my dreams will never come true because of this addiction that holds me back.\",\n          \"I\\\"m nervous about sharing such personal details, but I also recognize the importance of connecting with others who have been through similar situations. It might be worth taking that step and opening up to them.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gpt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          \"That\\\"s a great approach. It\\\"s important to honor your own pace and take small steps towards growth. How do you envision life being different once you feel more comfortable embracing vulnerability?\",\n          \"Thank you for sharing that with me. I can sense your fear, but I want you to know that there is always hope. Let\\\"s focus on finding solutions together. What is it that you dream of?\",\n          \"It\\\"s completely understandable to long for the past and the comfort of what was familiar. Grieving is a process, and it takes time to adapt to life without our loved ones. Are there any specific memories or moments with your boyfriend that bring you comfort?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5cf4aee5-1bec-4c21-9bf3-bd3bc4c9133e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I\"ve been feeling so sad and overwhelmed latel...</td>\n",
       "      <td>Hey there, I\"m here to listen and support you....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently got a promotion at work, which I th...</td>\n",
       "      <td>I can understand how it can be overwhelming wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, the workload has increased significantly...</td>\n",
       "      <td>It sounds like you\"re dealing with a lot of pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I\"ve been trying to prioritize my tasks and de...</td>\n",
       "      <td>It\"s great to hear that you\"re already impleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You\"re right. I haven\"t really opened up about...</td>\n",
       "      <td>It\"s completely normal to feel that way, but r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cf4aee5-1bec-4c21-9bf3-bd3bc4c9133e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5cf4aee5-1bec-4c21-9bf3-bd3bc4c9133e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5cf4aee5-1bec-4c21-9bf3-bd3bc4c9133e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b10612bb-76e0-4bb7-b840-c5c6b9ac312e\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b10612bb-76e0-4bb7-b840-c5c6b9ac312e')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b10612bb-76e0-4bb7-b840-c5c6b9ac312e button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               human  \\\n",
       "0  I\"ve been feeling so sad and overwhelmed latel...   \n",
       "1  I recently got a promotion at work, which I th...   \n",
       "2  Well, the workload has increased significantly...   \n",
       "3  I\"ve been trying to prioritize my tasks and de...   \n",
       "4  You\"re right. I haven\"t really opened up about...   \n",
       "\n",
       "                                                 gpt  \n",
       "0  Hey there, I\"m here to listen and support you....  \n",
       "1  I can understand how it can be overwhelming wh...  \n",
       "2  It sounds like you\"re dealing with a lot of pr...  \n",
       "3  It\"s great to hear that you\"re already impleme...  \n",
       "4  It\"s completely normal to feel that way, but r...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dPsYJO8pnRFe"
   },
   "outputs": [],
   "source": [
    "data.rename(columns={'human': 'input', 'gpt': 'output'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "jXMll6ZMnNRI",
    "outputId": "7179ca4c-d45f-48c3-9edf-2e9cc66a3460"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"*deep breath* I can already feel some tension releasing.\",\n          \"I\\\"m afraid, therapist. Afraid that my dreams will never come true because of this addiction that holds me back.\",\n          \"I\\\"m nervous about sharing such personal details, but I also recognize the importance of connecting with others who have been through similar situations. It might be worth taking that step and opening up to them.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1999,\n        \"samples\": [\n          \"That\\\"s a great approach. It\\\"s important to honor your own pace and take small steps towards growth. How do you envision life being different once you feel more comfortable embracing vulnerability?\",\n          \"Thank you for sharing that with me. I can sense your fear, but I want you to know that there is always hope. Let\\\"s focus on finding solutions together. What is it that you dream of?\",\n          \"It\\\"s completely understandable to long for the past and the comfort of what was familiar. Grieving is a process, and it takes time to adapt to life without our loved ones. Are there any specific memories or moments with your boyfriend that bring you comfort?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f08adca2-43c5-4842-9800-049cc07f4d7c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I\"ve been feeling so sad and overwhelmed latel...</td>\n",
       "      <td>Hey there, I\"m here to listen and support you....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently got a promotion at work, which I th...</td>\n",
       "      <td>I can understand how it can be overwhelming wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, the workload has increased significantly...</td>\n",
       "      <td>It sounds like you\"re dealing with a lot of pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I\"ve been trying to prioritize my tasks and de...</td>\n",
       "      <td>It\"s great to hear that you\"re already impleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You\"re right. I haven\"t really opened up about...</td>\n",
       "      <td>It\"s completely normal to feel that way, but r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>I would appreciate guidance on how to express ...</td>\n",
       "      <td>I understand, Charlie. It\"s important to conve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Ideally, I would love for us to have a calm an...</td>\n",
       "      <td>It sounds like you\"re seeking a cooperative an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Thank you, Alex. This conversation has given m...</td>\n",
       "      <td>It was my pleasure, Charlie. Remember, you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>I\"m feeling so sad, Alex. My fiancee recently ...</td>\n",
       "      <td>I\"m truly sorry to hear about your breakup, Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Thank you, Alex. I appreciate your empathy and...</td>\n",
       "      <td>It sounds like painting had a significant impa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f08adca2-43c5-4842-9800-049cc07f4d7c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f08adca2-43c5-4842-9800-049cc07f4d7c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f08adca2-43c5-4842-9800-049cc07f4d7c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-5e5cbca9-7664-4e41-b0ee-d4633abd85dc\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e5cbca9-7664-4e41-b0ee-d4633abd85dc')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-5e5cbca9-7664-4e41-b0ee-d4633abd85dc button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_616ee226-3903-49f7-bc23-1d851415a073\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_616ee226-3903-49f7-bc23-1d851415a073 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('data');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     I\"ve been feeling so sad and overwhelmed latel...   \n",
       "1     I recently got a promotion at work, which I th...   \n",
       "2     Well, the workload has increased significantly...   \n",
       "3     I\"ve been trying to prioritize my tasks and de...   \n",
       "4     You\"re right. I haven\"t really opened up about...   \n",
       "...                                                 ...   \n",
       "1995  I would appreciate guidance on how to express ...   \n",
       "1996  Ideally, I would love for us to have a calm an...   \n",
       "1997  Thank you, Alex. This conversation has given m...   \n",
       "1998  I\"m feeling so sad, Alex. My fiancee recently ...   \n",
       "1999  Thank you, Alex. I appreciate your empathy and...   \n",
       "\n",
       "                                                 output  \n",
       "0     Hey there, I\"m here to listen and support you....  \n",
       "1     I can understand how it can be overwhelming wh...  \n",
       "2     It sounds like you\"re dealing with a lot of pr...  \n",
       "3     It\"s great to hear that you\"re already impleme...  \n",
       "4     It\"s completely normal to feel that way, but r...  \n",
       "...                                                 ...  \n",
       "1995  I understand, Charlie. It\"s important to conve...  \n",
       "1996  It sounds like you\"re seeking a cooperative an...  \n",
       "1997  It was my pleasure, Charlie. Remember, you hav...  \n",
       "1998  I\"m truly sorry to hear about your breakup, Ch...  \n",
       "1999  It sounds like painting had a significant impa...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aL3JTAMTfQ9"
   },
   "source": [
    "### Stastical Information about Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GQpMW8zQnEZ7"
   },
   "outputs": [],
   "source": [
    "# Function to calculate unique words and average sentence length\n",
    "def text_statistics(column):\n",
    "    word_count = column.str.split().apply(len)\n",
    "    unique_words = len(set(\" \".join(column).split()))\n",
    "    avg_length = word_count.mean()\n",
    "    return unique_words, avg_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hPpGZ8drnEco"
   },
   "outputs": [],
   "source": [
    "# Calculate statistics for input and output columns\n",
    "input_unique_words, input_avg_length = text_statistics(data['input'])\n",
    "output_unique_words, output_avg_length = text_statistics(data['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zrxYuuYnEgL",
    "outputId": "899f81c0-0833-49c9-91a5-5bcf1ddfc4da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Column: 5694 unique words, Avg Sentence Length: 37.812\n",
      "Output Column: 5256 unique words, Avg Sentence Length: 42.3335\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input Column: {input_unique_words} unique words, Avg Sentence Length: {input_avg_length}\")\n",
    "print(f\"Output Column: {output_unique_words} unique words, Avg Sentence Length: {output_avg_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJrUmrYnTmge"
   },
   "source": [
    "Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ERSKUUu5m4-N"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80-20 split)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Jt9AW16m5A9",
    "outputId": "020f4b04-004c-425d-c39b-ffe988ead907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 1600, Testing Set Size: 400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Training Set Size: {len(train_data)}, Testing Set Size: {len(test_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUwOKoX4TuIW"
   },
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkKXO5W9T5lT"
   },
   "source": [
    "Steps :\n",
    "\n",
    "   1. Lowercasing all text for uniformity.\n",
    "   2. Contraction expansion (e.g., \"can't\" → \"cannot\", \"I'm\" → \"I am\").\n",
    "   3. Replacing slang terms (e.g., \"u\" → \"you\", \"brb\" → \"be right back\").\n",
    "   4. Removing special characters to retain only alphanumeric text.\n",
    "   5. Lemmatizing words to their base forms (e.g., \"running\" → \"run\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xJASAwFhmhvQ"
   },
   "outputs": [],
   "source": [
    "contractions = {\n",
    "    \"what's\": \"what is\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"here's\": \"here is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"there'll\": \"there will\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"he's\": \"he has\",\n",
    "    \"she's\": \"she has\",\n",
    "    \"it's\": \"it has\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"who're\": \"who are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"ain't\": \"is not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"daren't\": \"dare not\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"ma'am\": \"madam\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xE-xsgEQmhyU"
   },
   "outputs": [],
   "source": [
    "\n",
    "slang_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"ur\": \"your\",\n",
    "    \"y\": \"why\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"plz\": \"please\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"b4\": \"before\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"idk\": \"i do not know\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"wtf\": \"what the heck\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"imho\": \"in my humble opinion\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bc\": \"because\",\n",
    "    \"bff\": \"best friends forever\",\n",
    "    \"cya\": \"see you\",\n",
    "    \"dm\": \"direct message\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"k\": \"okay\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"nvm\": \"never mind\",\n",
    "    \"omw\": \"on my way\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"wyd\": \"what are you doing\",\n",
    "    \"wya\": \"where are you at\",\n",
    "    \"afaik\": \"as far as i know\",\n",
    "    \"ikr\": \"i know right\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"thnx\": \"thanks\",\n",
    "    \"sup\": \"what is up\",\n",
    "    \"wbu\": \"what about you\",\n",
    "    \"b4n\": \"bye for now\",\n",
    "    \"g2g\": \"got to go\",\n",
    "    \"ty\": \"thank you\",\n",
    "    \"yw\": \"you are welcome\",\n",
    "    \"xoxo\": \"hugs and kisses\",\n",
    "    \"afaik\": \"as far as i know\",\n",
    "    \"atm\": \"at the moment\",\n",
    "    \"bbl\": \"be back later\",\n",
    "    \"ftw\": \"for the win\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"icymi\": \"in case you missed it\",\n",
    "    \"idc\": \"i do not care\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"noob\": \"newbie\",\n",
    "    \"nsfw\": \"not safe for work\",\n",
    "    \"tldr\": \"too long did not read\",\n",
    "    \"yo\": \"hello\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"gratz\": \"congratulations\",\n",
    "    \"meh\": \"whatever\",\n",
    "    \"ez\": \"easy\",\n",
    "    \"prolly\": \"probably\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RtJRVPA5mh4o"
   },
   "outputs": [],
   "source": [
    "# Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Perform text preprocessing: fix structural issues, lowercase, expand contractions,\n",
    "    replace slang, remove special characters, lemmatize text.\n",
    "    \"\"\"\n",
    "    # Step 1: Fix double quotes\n",
    "    def fix_double_quotes(t):\n",
    "        \"\"\"\n",
    "        Replace double quotes used in contractions with apostrophes.\n",
    "        Example: i\"ve -> i've\n",
    "        \"\"\"\n",
    "        return re.sub(r'(\\w)\"(\\w)', r\"\\1'\\2\", t)\n",
    "\n",
    "    text = text.apply(fix_double_quotes)\n",
    "\n",
    "    # Step 2: Lowercase the text\n",
    "    text = text.str.lower()\n",
    "\n",
    "    # Step 3: Expand contractions\n",
    "    def expand_contractions(t):\n",
    "        \"\"\"\n",
    "        Expand contractions using the contractions dictionary.\n",
    "        \"\"\"\n",
    "        for contraction, expansion in contractions.items():\n",
    "            t = re.sub(rf\"\\b{re.escape(contraction)}\\b\", expansion, t)\n",
    "        return t\n",
    "\n",
    "    text = text.apply(expand_contractions)\n",
    "\n",
    "    # Step 4: Replace slang\n",
    "    def replace_slang(t):\n",
    "        \"\"\"\n",
    "        Replace slang words using the slang dictionary.\n",
    "        \"\"\"\n",
    "        for slang, full_form in slang_dict.items():\n",
    "            t = re.sub(rf\"\\b{re.escape(slang)}\\b\", full_form, t)\n",
    "        return t\n",
    "\n",
    "    text = text.apply(replace_slang)\n",
    "\n",
    "    # Step 5: Remove special characters\n",
    "    text = text.apply(lambda x: re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", x))\n",
    "\n",
    "    # Step 6: Lemmatization\n",
    "    def lemmatize_text(t):\n",
    "        \"\"\"\n",
    "        Lemmatize words to their base form.\n",
    "        \"\"\"\n",
    "        words = t.split()  # Split into tokens\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        return \" \".join(lemmatized_words)  # Join back into a string\n",
    "\n",
    "    text = text.apply(lemmatize_text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yo7dXlw8mbU0"
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "train_data['input'] = preprocess_text(train_data['input'])\n",
    "train_data['output'] = preprocess_text(train_data['output'])\n",
    "test_data['input'] = preprocess_text(test_data['input'])\n",
    "test_data['output'] = preprocess_text(test_data['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tccDa-SNwf0f"
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOeunZkOUExi"
   },
   "source": [
    "* Adding and tokens to define sentence boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_saFzy5Vmbv_"
   },
   "outputs": [],
   "source": [
    "start_token = '<start>'\n",
    "end_token = '<end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BVSfCQetoO_a"
   },
   "outputs": [],
   "source": [
    "# Function to add <start> and <end> token\n",
    "def add_special_tokens(texts):\n",
    "    return texts.apply(lambda text: f\"{start_token} {text} {end_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qb1Q7dnMoPC0"
   },
   "outputs": [],
   "source": [
    "train_data['input'] = add_special_tokens(train_data['input'])\n",
    "train_data['output'] = add_special_tokens(train_data['output'])\n",
    "test_data['input'] = add_special_tokens(test_data['input'])\n",
    "test_data['output'] = add_special_tokens(test_data['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RldoAXzHUObA"
   },
   "source": [
    "\n",
    "  * Tokenizing text into individual words.\n",
    "  * Handling out-of-vocabulary (OOV) words with token.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TOmHSCMln5Co"
   },
   "outputs": [],
   "source": [
    "# Tokenizer setup for both input and output\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(pd.concat([train_data['input'], train_data['output']]))\n",
    "\n",
    "# Add <start> and <end> tokens to the word_index\n",
    "start_token = '<start>'\n",
    "end_token = '<end>'\n",
    "\n",
    "if start_token not in tokenizer.word_index:\n",
    "    tokenizer.word_index[start_token] = len(tokenizer.word_index) + 1\n",
    "if end_token not in tokenizer.word_index:\n",
    "   tokenizer.word_index[end_token] = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Update vocab size to include the new tokens\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KW9uiyAdn5FX",
    "outputId": "2b51a12c-d9ec-4cc3-c1fd-699b23c9b05b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3667\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EKe9PSlQn5IZ"
   },
   "outputs": [],
   "source": [
    "# Convert text to sequences\n",
    "train_input_seq = tokenizer.texts_to_sequences(train_data['input'])\n",
    "train_output_seq = tokenizer.texts_to_sequences(train_data['output'])\n",
    "test_input_seq = tokenizer.texts_to_sequences(test_data['input'])\n",
    "test_output_seq = tokenizer.texts_to_sequences(test_data['output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0iCDIv3n5LK",
    "outputId": "2a47bf33-2a03-4e49-f646-f5baf6124c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokenized input sequence: [6, 434, 1441, 22, 12, 755, 13, 163, 414, 13, 1173, 12, 153, 1113, 13, 50, 434, 1795, 22, 2, 493, 16, 519, 4, 2074, 16, 229, 198, 361, 36, 106, 72, 2551, 756, 475, 18, 22, 2552, 16, 366, 4, 1575, 22, 302, 2, 1342, 50, 932, 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample tokenized input sequence:\", train_input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNCZn6mdUWYg"
   },
   "source": [
    "* Padding/truncating sequences to a fixed length (MAX_LEN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "XZcSExeGn5N_"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 50  # Set a maximum sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rP1SW8VAn5Q0"
   },
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "train_input_padded = pad_sequences(train_input_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "train_output_padded = pad_sequences(train_output_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "test_input_padded = pad_sequences(test_input_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "test_output_padded = pad_sequences(test_output_seq, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2EWGjV-n5UY",
    "outputId": "06bd593e-a3cc-4373-9722-e9c5c77741a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Input Shape: (1600, 50), Train Output Shape: (1600, 50)\n",
      "Test Input Shape: (400, 50), Test Output Shape: (400, 50)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Input Shape: {train_input_padded.shape}, Train Output Shape: {train_output_padded.shape}\")\n",
    "print(f\"Test Input Shape: {test_input_padded.shape}, Test Output Shape: {test_output_padded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tz4zBvKjw2Ne"
   },
   "source": [
    "# Relative Position Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hr07X6-44Rgp"
   },
   "outputs": [],
   "source": [
    "def relative_position_encoding(max_len, embed_dim):\n",
    "    positions = tf.range(max_len, dtype=tf.float32)\n",
    "    relative_positions = tf.range(max_len, dtype=tf.float32)[:, None] - tf.range(max_len, dtype=tf.float32)[None, :]\n",
    "    angle_rates = 1 / (10000 ** (2 * (tf.range(embed_dim // 2, dtype=tf.float32)) / embed_dim))\n",
    "    angle_rads = relative_positions[..., None] * angle_rates[None, None, :]\n",
    "    sin_encoding = tf.math.sin(angle_rads)\n",
    "    cos_encoding = tf.math.cos(angle_rads)\n",
    "    relative_encoding = tf.concat([sin_encoding, cos_encoding], axis=-1)\n",
    "    return relative_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kGahPB1UbXo"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "EIyK0qTT4YRY"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embed_dim, num_heads, ff_dim, max_len, num_encoder_layers, num_decoder_layers):\n",
    "\n",
    "    # Encoder Inputs\n",
    "    encoder_inputs = Input(shape=(max_len,))\n",
    "    encoder_embedding = Embedding(vocab_size, embed_dim)(encoder_inputs)\n",
    "\n",
    "    # Compute Relative Positional Encoding\n",
    "    relative_positions = relative_position_encoding(max_len, embed_dim)  # Shape: (max_len, max_len, embed_dim)\n",
    "    relative_positions = tf.expand_dims(relative_positions, axis=0)  # Add batch axis: (1, max_len, max_len, embed_dim)\n",
    "\n",
    "    # Encoder Layers\n",
    "    encoder_output = encoder_embedding\n",
    "    for _ in range(num_encoder_layers):\n",
    "        # Multi-Head Attention\n",
    "        attn_layer = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        attn_output = attn_layer(encoder_output, encoder_output)\n",
    "\n",
    "        # Broadcast relative positions to match batch size\n",
    "        batch_size = tf.shape(encoder_output)[0]\n",
    "        broadcast_relative_positions = tf.broadcast_to(relative_positions, [batch_size, *relative_positions.shape[1:]])\n",
    "\n",
    "        # Compute relative position adjustment for attention\n",
    "        pos_adjustment = tf.reduce_sum(broadcast_relative_positions, axis=2)  # Shape: (batch_size, max_len, embed_dim)\n",
    "        attn_output += pos_adjustment\n",
    "\n",
    "        # Residual Connection and Layer Normalization\n",
    "        encoder_output = LayerNormalization()(attn_output + encoder_output)\n",
    "\n",
    "        # Feedforward Layer with Projection\n",
    "        ff_layer = Dense(ff_dim, activation='relu')(encoder_output)\n",
    "        ff_projected = Dense(embed_dim)(ff_layer)  # Project back to embed_dim for residual connection\n",
    "        encoder_output = LayerNormalization()(ff_projected + encoder_output)\n",
    "\n",
    "    # Decoder Inputs\n",
    "    decoder_inputs = Input(shape=(max_len,))\n",
    "    decoder_embedding = Embedding(vocab_size, embed_dim)(decoder_inputs)\n",
    "\n",
    "    # Decoder Layers\n",
    "    decoder_output = decoder_embedding\n",
    "    for _ in range(num_decoder_layers):\n",
    "        # Self-Attention Mechanism\n",
    "        self_attn_layer = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self_attn_output = self_attn_layer(decoder_output, decoder_output)\n",
    "\n",
    "        # Broadcast relative positions to match batch size\n",
    "        broadcast_relative_positions = tf.broadcast_to(relative_positions, [batch_size, *relative_positions.shape[1:]])\n",
    "\n",
    "        # Compute relative position adjustment for self-attention\n",
    "        pos_adjustment = tf.reduce_sum(broadcast_relative_positions, axis=2)  # Shape: (batch_size, max_len, embed_dim)\n",
    "        self_attn_output += pos_adjustment\n",
    "\n",
    "        # Residual Connection and Layer Normalization\n",
    "        self_attn_output = LayerNormalization()(self_attn_output + decoder_output)\n",
    "\n",
    "        # Cross-Attention Mechanism\n",
    "        cross_attn_layer = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        cross_attn_output = cross_attn_layer(self_attn_output, encoder_output)\n",
    "\n",
    "        # Residual Connection and Layer Normalization\n",
    "        decoder_output = LayerNormalization()(cross_attn_output + self_attn_output)\n",
    "\n",
    "        # Feedforward Layer with Projection\n",
    "        ff_layer = Dense(ff_dim, activation='relu')(decoder_output)\n",
    "        ff_projected = Dense(embed_dim)(ff_layer)  # Project back to embed_dim for residual connection\n",
    "        decoder_output = LayerNormalization()(ff_projected + decoder_output)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder_output)\n",
    "\n",
    "    # Define the Model\n",
    "    return Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Ppr48qftokb3"
   },
   "outputs": [],
   "source": [
    "# Prepare decoder targets by shifting sequences\n",
    "train_output_padded_shifted = np.zeros_like(train_output_padded)\n",
    "test_output_padded_shifted = np.zeros_like(test_output_padded)\n",
    "\n",
    "# Shift each sequence to the left by 1 position\n",
    "train_output_padded_shifted[:, :-1] = train_output_padded[:, 1:]\n",
    "test_output_padded_shifted[:, :-1] = test_output_padded[:, 1:]\n",
    "\n",
    "# Ensure the last token is set to 0 (padding token) after the shift\n",
    "train_output_padded_shifted[:, -1] = 0\n",
    "test_output_padded_shifted[:, -1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-Pn0DsTokew",
    "outputId": "f6411368-8cba-4119-927b-a9cc4ab0da6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Output Shifted Data Type: int32\n",
      "Test Output Shifted Data Type: int32\n"
     ]
    }
   ],
   "source": [
    "# Check the data type of shifted sequences\n",
    "print(\"Train Output Shifted Data Type:\", train_output_padded_shifted.dtype)  # Should be int32 or int64\n",
    "print(\"Test Output Shifted Data Type:\", test_output_padded_shifted.dtype)  # Should be int32 or int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "oB1DBT7O4c-i"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "EMBED_DIM = 512\n",
    "NUM_HEADS = 2\n",
    "FF_DIM = 1048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "B9MoBKTt4hWy"
   },
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = build_model(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    max_len=MAX_LEN,\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LriU1GVWxYfp",
    "outputId": "e2521c4c-6b4e-44bc-f74a-1db3da8426d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 50, 512)              1877504   ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_2 (TFOp  (3,)                         0         ['embedding_2[0][0]']         \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_2[0][0]']\n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.broadcast_to_4 (TFOpLam  (None, 50, 50, 512)          0         ['tf.__operators__.getitem_2[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, 50, 512)              2100736   ['embedding_2[0][0]',         \n",
      " ltiHeadAttention)                                                   'embedding_2[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_4 (TFOp  (None, 50, 512)              0         ['tf.broadcast_to_4[0][0]']   \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (T  (None, 50, 512)              0         ['multi_head_attention_6[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.math.reduce_sum_4[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (T  (None, 50, 512)              0         ['tf.__operators__.add_14[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'embedding_2[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, 50, 512)              1024      ['tf.__operators__.add_15[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 50, 1048)             537624    ['layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 50, 512)              537088    ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (T  (None, 50, 512)              0         ['dense_10[0][0]',            \n",
      " FOpLambda)                                                          'layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, 50, 512)              1024      ['tf.__operators__.add_16[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_3 (TFOp  (3,)                         0         ['layer_normalization_11[0][0]\n",
      " Lambda)                                                            ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  ()                           0         ['tf.compat.v1.shape_3[0][0]']\n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.broadcast_to_5 (TFOpLam  (None, 50, 50, 512)          0         ['tf.__operators__.getitem_3[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 50, 512)              2100736   ['layer_normalization_11[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_5 (TFOp  (None, 50, 512)              0         ['tf.broadcast_to_5[0][0]']   \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (T  (None, 50, 512)              0         ['multi_head_attention_7[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.math.reduce_sum_5[0][0]']\n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (T  (None, 50, 512)              0         ['tf.__operators__.add_17[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 50, 512)              1877504   ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " tf.broadcast_to_6 (TFOpLam  (None, 50, 50, 512)          0         ['tf.__operators__.getitem_3[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, 50, 512)              1024      ['tf.__operators__.add_18[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, 50, 512)              2100736   ['embedding_3[0][0]',         \n",
      " ltiHeadAttention)                                                   'embedding_3[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_6 (TFOp  (None, 50, 512)              0         ['tf.broadcast_to_6[0][0]']   \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 50, 1048)             537624    ['layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (T  (None, 50, 512)              0         ['multi_head_attention_8[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.math.reduce_sum_6[0][0]']\n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 50, 512)              537088    ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (T  (None, 50, 512)              0         ['tf.__operators__.add_20[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'embedding_3[0][0]']         \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (T  (None, 50, 512)              0         ['dense_12[0][0]',            \n",
      " FOpLambda)                                                          'layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, 50, 512)              1024      ['tf.__operators__.add_21[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, 50, 512)              1024      ['tf.__operators__.add_19[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (Mu  (None, 50, 512)              2100736   ['layer_normalization_14[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (T  (None, 50, 512)              0         ['multi_head_attention_9[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, 50, 512)              1024      ['tf.__operators__.add_22[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 50, 1048)             537624    ['layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 50, 512)              537088    ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (T  (None, 50, 512)              0         ['dense_14[0][0]',            \n",
      " FOpLambda)                                                          'layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, 50, 512)              1024      ['tf.__operators__.add_23[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " tf.broadcast_to_7 (TFOpLam  (None, 50, 50, 512)          0         ['tf.__operators__.getitem_3[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (M  (None, 50, 512)              2100736   ['layer_normalization_16[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_7 (TFOp  (None, 50, 512)              0         ['tf.broadcast_to_7[0][0]']   \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (T  (None, 50, 512)              0         ['multi_head_attention_10[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'tf.math.reduce_sum_7[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (T  (None, 50, 512)              0         ['tf.__operators__.add_24[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (None, 50, 512)              1024      ['tf.__operators__.add_25[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (M  (None, 50, 512)              2100736   ['layer_normalization_17[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (T  (None, 50, 512)              0         ['multi_head_attention_11[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_18 (La  (None, 50, 512)              1024      ['tf.__operators__.add_26[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 50, 1048)             537624    ['layer_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 50, 512)              537088    ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (T  (None, 50, 512)              0         ['dense_16[0][0]',            \n",
      " FOpLambda)                                                          'layer_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_19 (La  (None, 50, 512)              1024      ['tf.__operators__.add_27[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 50, 3667)             1881171   ['layer_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22549683 (86.02 MB)\n",
      "Trainable params: 22549683 (86.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ij7YmN31UES",
    "outputId": "86d5a0d2-455b-4189-d5b1-79fa23c6fd12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "13/13 [==============================] - 240s 18s/step - loss: 5.7083 - accuracy: 0.1645 - val_loss: 5.1277 - val_accuracy: 0.1940\n",
      "Epoch 2/15\n",
      "13/13 [==============================] - 224s 17s/step - loss: 5.1021 - accuracy: 0.1864 - val_loss: 5.0228 - val_accuracy: 0.1903\n",
      "Epoch 3/15\n",
      "13/13 [==============================] - 225s 17s/step - loss: 5.0086 - accuracy: 0.1863 - val_loss: 5.0047 - val_accuracy: 0.1928\n",
      "Epoch 4/15\n",
      "13/13 [==============================] - 229s 18s/step - loss: 4.9756 - accuracy: 0.1886 - val_loss: 4.9715 - val_accuracy: 0.1956\n",
      "Epoch 5/15\n",
      "13/13 [==============================] - 224s 17s/step - loss: 4.9476 - accuracy: 0.1898 - val_loss: 4.9572 - val_accuracy: 0.1957\n",
      "Epoch 6/15\n",
      "13/13 [==============================] - 218s 17s/step - loss: 4.9295 - accuracy: 0.1888 - val_loss: 4.9554 - val_accuracy: 0.1955\n",
      "Epoch 7/15\n",
      "13/13 [==============================] - 216s 17s/step - loss: 4.9217 - accuracy: 0.1891 - val_loss: 4.9486 - val_accuracy: 0.1973\n",
      "Epoch 8/15\n",
      "13/13 [==============================] - 218s 17s/step - loss: 4.9131 - accuracy: 0.1911 - val_loss: 4.9644 - val_accuracy: 0.1995\n",
      "Epoch 9/15\n",
      "13/13 [==============================] - 216s 17s/step - loss: 4.9116 - accuracy: 0.1912 - val_loss: 4.9512 - val_accuracy: 0.1986\n",
      "Epoch 10/15\n",
      "13/13 [==============================] - 215s 17s/step - loss: 4.8995 - accuracy: 0.1925 - val_loss: 4.9536 - val_accuracy: 0.1981\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Train the Model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    [train_input_padded, train_output_padded],\n",
    "    train_output_padded_shifted,\n",
    "    validation_data=([test_input_padded, test_output_padded], test_output_padded_shifted),\n",
    "    batch_size=128,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ubxdr4bFUior"
   },
   "source": [
    "# Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydrSC0mf1UHs",
    "outputId": "fad9ae1f-627b-4d4e-86e7-28ebb091d56d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 27s 2s/step - loss: 4.9486 - accuracy: 0.1973\n",
      "Test Loss: 4.948615074157715\n",
      "Test Accuracy: 0.1973000019788742\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    [test_input_padded, test_output_padded], test_output_padded_shifted\n",
    ")\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEgHZ8V2Qd85",
    "outputId": "89fbb4e4-63ea-4681-f88d-b06d20e066a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "#model.save('path_to_your_model.h5', save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "JBJ0WW4GaxDY"
   },
   "outputs": [],
   "source": [
    "# Save the tokenizer\n",
    "#import pickle\n",
    "#with open('path_to_tokenizer.pkl', 'wb') as handle:\n",
    "#    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "EvyBW8VeQeAT"
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention\n",
    "\n",
    "# Load the model with a custom object scope\n",
    "#custom_objects = {\n",
    "#    \"LayerNormalization\": LayerNormalization,\n",
    "#    \"MultiHeadAttention\": MultiHeadAttention,\n",
    "#}\n",
    "\n",
    "#model = load_model('/content/path_to_your_model.h5', custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92ENyVyKMVwO"
   },
   "source": [
    "# Accuracy vs Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Tw8ugFG-okkd",
    "outputId": "32898374-35ae-479d-c5d5-71ec4edb3889"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Accuracy vs Validation Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LANrq9eVMdeq"
   },
   "source": [
    "# Loss vs Validation_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "udkZ7C4qBSzc",
    "outputId": "2d6398dc-55d4-45cc-8a5f-b19de70172ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Training Loss vs Validation Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRtYkvoTlXfl"
   },
   "source": [
    "# Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "fY0hdTThoKVy"
   },
   "outputs": [],
   "source": [
    "# ## Prediction\n",
    "\n",
    "def predict(input_text, model, tokenizer, max_len):\n",
    "    \"\"\"\n",
    "    Generate a response using the trained chatbot model.\n",
    "\n",
    "    Args:\n",
    "    - input_text (str): User input text.\n",
    "    - model: Trained chatbot model.\n",
    "    - tokenizer: Tokenizer used during training.\n",
    "    - max_len (int): Maximum sequence length.\n",
    "\n",
    "    Returns:\n",
    "    - str: Generated response.\n",
    "    \"\"\"\n",
    "    # Preprocess input text\n",
    "    input_seq = tokenizer.texts_to_sequences([input_text.lower()])\n",
    "    input_padded = pad_sequences(input_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "    # Initialize decoder input with the start token\n",
    "    start_token = tokenizer.word_index.get('<start>', 1)  # Default to 1\n",
    "    decoder_input = np.zeros((1, max_len))\n",
    "    decoder_input[0, 0] = start_token\n",
    "\n",
    "    response_tokens = []\n",
    "    for i in range(1, max_len):\n",
    "        # Predict next token\n",
    "        predictions = model.predict([input_padded, decoder_input])\n",
    "        predicted_token = np.argmax(predictions[0, i - 1, :])\n",
    "\n",
    "        # Stop if the end token is predicted\n",
    "        if predicted_token == tokenizer.word_index.get('<end>', 0):  # Default to 0\n",
    "            break\n",
    "\n",
    "        response_tokens.append(predicted_token)\n",
    "        decoder_input[0, i] = predicted_token\n",
    "\n",
    "    # Decode tokens to text\n",
    "    response = tokenizer.sequences_to_texts([response_tokens])[0]\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "KVsQq0wnkxlx"
   },
   "outputs": [],
   "source": [
    "# Example Predictions\n",
    "user_inputs = [\n",
    "    \"I feel stressed and overwhelmed with work.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRCF26u-oT_s",
    "outputId": "f2ac77b0-a2fc-4a90-e6da-93faa37f3d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 776ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "User: I feel stressed and overwhelmed with work.\n",
      "Chatbot: it it it it it you to to to to you you you you you you you you you you you you you you you you <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "for user_input in user_inputs:\n",
    "    response = predict(user_input, model, tokenizer, MAX_LEN)\n",
    "    print(f\"User: {user_input}\")\n",
    "    print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJljOecJml88"
   },
   "source": [
    "# ROUGE-L Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "AaFO_D3JqOKP"
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "# Initialize ROUGE scorer\n",
    "rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "TThl0gwfqONC"
   },
   "outputs": [],
   "source": [
    "# Efficient ROUGE-L computation\n",
    "def compute_rouge_l(reference_texts, predicted_texts):\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    for ref, pred in zip(reference_texts, predicted_texts):\n",
    "        score = rouge_scorer_obj.score(ref, pred)['rougeL'].fmeasure\n",
    "        total_score += score\n",
    "        count += 1\n",
    "    return total_score / count if count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "cG4KCAYNqOP2"
   },
   "outputs": [],
   "source": [
    "# Sample a subset of the test data (e.g., 10 examples for quick testing)\n",
    "sample_size = 10\n",
    "test_sample = test_data.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Optimized predictions using batching\n",
    "def generate_predictions(sample_data, model, tokenizer, max_len):\n",
    "    predictions = []\n",
    "    for input_text in sample_data['input']:\n",
    "        # Generate response for each input\n",
    "        response = predict(input_text, model, tokenizer, max_len)\n",
    "        predictions.append(response)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5ZaCkbYqOSz",
    "outputId": "2f501de1-657c-4273-e760-0894a79c0cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "ROUGE-L Score (Sample of 10): 0.08420413243287107\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test sample\n",
    "predicted_responses = generate_predictions(test_sample, model, tokenizer, MAX_LEN)\n",
    "\n",
    "# Compute ROUGE-L for the sample\n",
    "rouge_l_score = compute_rouge_l(test_sample['output'].tolist(), predicted_responses)\n",
    "print(f\"ROUGE-L Score (Sample of {sample_size}): {rouge_l_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g0lsQYYqup1"
   },
   "source": [
    "# BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYxHsCNR3l02"
   },
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "import numpy as np\n",
    "\n",
    "def optimized_bert_score(test_data, sample_size, model, tokenizer, max_len):\n",
    "    \"\"\"\n",
    "    Optimize BERT score computation by batching predictions and using a subset of data.\n",
    "\n",
    "    Args:\n",
    "    - test_data (DataFrame): The test dataset with 'input' and 'output' columns.\n",
    "    - sample_size (int): Number of samples to evaluate.\n",
    "    - model (Model): The trained model for generating predictions.\n",
    "    - tokenizer (Tokenizer): Tokenizer for text preprocessing.\n",
    "    - max_len (int): Maximum sequence length for padding.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Average Precision, Recall, and F1 scores.\n",
    "    \"\"\"\n",
    "    # Sample a subset of the test data\n",
    "    test_sample = test_data.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    # Extract inputs and references\n",
    "    inputs = test_sample['input'].tolist()\n",
    "    references = test_sample['output'].tolist()\n",
    "\n",
    "    # Batch predictions to optimize performance\n",
    "    batch_size = 64\n",
    "    predictions = []\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "        batch_inputs = inputs[i:i + batch_size]\n",
    "        batch_predictions = [\n",
    "            predict(input_text, model, tokenizer, max_len) for input_text in batch_inputs\n",
    "        ]\n",
    "        predictions.extend(batch_predictions)\n",
    "\n",
    "    # Compute BERT Score\n",
    "    P, R, F1 = score(predictions, references, lang=\"en\", verbose=False, rescale_with_baseline=False)\n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_scores = {\n",
    "        \"Precision\": np.mean(P.numpy()),\n",
    "        \"Recall\": np.mean(R.numpy()),\n",
    "        \"F1\": np.mean(F1.numpy())\n",
    "    }\n",
    "\n",
    "    return avg_scores\n",
    "\n",
    "# Example Usage\n",
    "sample_size = 10\n",
    "scores = optimized_bert_score(test_data, sample_size, model, tokenizer, MAX_LEN)\n",
    "print(f\"BERT Precision (Sample): {scores['Precision']:.4f}\")\n",
    "print(f\"BERT Recall (Sample): {scores['Recall']:.4f}\")\n",
    "print(f\"BERT F1 (Sample): {scores['F1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WD61At6qqObE"
   },
   "outputs": [],
   "source": [
    "# Extract references and predictions for the sample\n",
    "references = test_sample['output'].tolist()\n",
    "predictions = [predict(input_text, model, tokenizer, MAX_LEN) for input_text in test_sample['input']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDkATUzLqOeO"
   },
   "outputs": [],
   "source": [
    "# Compute BERT score for the sampled data\n",
    "P, R, F1 = score(predictions, references, lang=\"en\", verbose=True)\n",
    "\n",
    "# Display the results\n",
    "print(f\"BERT Precision (Sample): {P.mean().item():.4f}\")\n",
    "print(f\"BERT Recall (Sample): {R.mean().item():.4f}\")\n",
    "print(f\"BERT F1 (Sample): {F1.mean().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEwhKS6Nq7tD"
   },
   "source": [
    "# AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukU37z57qOhN"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_auc_optimized(model, test_input_padded, test_output_padded, test_output_padded_shifted, vocab_size, max_len, batch_size=500):\n",
    "\n",
    "    num_samples = test_input_padded.shape[0]\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Get batch start and end indices\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, num_samples)\n",
    "\n",
    "        # Get batch data\n",
    "        batch_input = test_input_padded[start_idx:end_idx]\n",
    "        batch_output = test_output_padded[start_idx:end_idx]\n",
    "        batch_true_labels = test_output_padded_shifted[start_idx:end_idx]\n",
    "\n",
    "        # Predict probabilities for the batch\n",
    "        batch_predictions = model.predict([batch_input, batch_output])  # Shape: (batch_size, max_len, vocab_size)\n",
    "\n",
    "        # Flatten predictions and true labels\n",
    "        batch_predictions = batch_predictions.reshape(-1, vocab_size)\n",
    "        batch_true_labels = batch_true_labels.flatten()\n",
    "\n",
    "        # Filter out padding indices\n",
    "        valid_indices = batch_true_labels != 0\n",
    "        batch_predictions = batch_predictions[valid_indices]\n",
    "        batch_true_labels = batch_true_labels[valid_indices]\n",
    "\n",
    "        # Append to lists\n",
    "        all_predictions.append(batch_predictions)\n",
    "        all_true_labels.append(batch_true_labels)\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "    # Compute AUC for each class\n",
    "    auc_scores = []\n",
    "    for class_idx in range(1, vocab_size):  # Exclude padding token (class 0)\n",
    "        class_true = (all_true_labels == class_idx).astype(int)  # Binary true labels for this class\n",
    "        if np.sum(class_true) > 0:  # Ensure at least one positive sample\n",
    "            class_auc = roc_auc_score(class_true, all_predictions[:, class_idx])\n",
    "            auc_scores.append(class_auc)\n",
    "\n",
    "    # Return the macro-average AUC\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "# Compute AUC for test data\n",
    "try:\n",
    "    auc_score = calculate_auc_optimized(\n",
    "        model,\n",
    "        test_input_padded,\n",
    "        test_output_padded,\n",
    "        test_output_padded_shifted,\n",
    "        VOCAB_SIZE,\n",
    "        MAX_LEN,\n",
    "        batch_size=60  # Adjust batch size for efficiency\n",
    "    )\n",
    "    print(f\"AUC Score: {auc_score}\")\n",
    "except MemoryError as e:\n",
    "    print(f\"Memory error encountered: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8FBcqTZrNeh"
   },
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbJcv0F1qOnS"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# Model Wrapper\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model, tokenizer, max_len):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def predict(self, texts, batch_size=100):\n",
    "        predictions = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "\n",
    "            # Tokenize and pad input texts\n",
    "            input_seq = self.tokenizer.texts_to_sequences(batch_texts)\n",
    "            input_padded = pad_sequences(input_seq, maxlen=self.max_len, padding='post', truncating='post')\n",
    "\n",
    "            # Create dummy decoder inputs (start token)\n",
    "            start_token = self.tokenizer.word_index.get('<start>', 1)\n",
    "            decoder_input = np.zeros((len(batch_texts), self.max_len))\n",
    "            decoder_input[:, 0] = start_token\n",
    "\n",
    "            # Predict probabilities for the batch\n",
    "            batch_predictions = self.model.predict([input_padded, decoder_input])  # Shape: (batch_size, max_len, vocab_size)\n",
    "\n",
    "            # Aggregate probabilities for each sequence\n",
    "            sequence_probs = np.mean(batch_predictions, axis=1)  # Shape: (batch_size, vocab_size)\n",
    "            predictions.append(sequence_probs)\n",
    "\n",
    "        # Concatenate predictions from all batches\n",
    "        return np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5bO0by1rGtS"
   },
   "outputs": [],
   "source": [
    "# Instantiate ModelWrapper\n",
    "model_wrapper = ModelWrapper(model, tokenizer, MAX_LEN)\n",
    "\n",
    "# Initialize LIME explainer\n",
    "#explainer = LimeTextExplainer(class_names=list(tokenizer.word_index.keys()))\n",
    "\n",
    "# Ensure LIME has valid class names\n",
    "explainer = LimeTextExplainer(class_names=[str(i) for i in range(len(tokenizer.word_index))])\n",
    "\n",
    "# Input text to explain\n",
    "input_text = \"I feel stressed and overwhelmed with work.\"\n",
    "\n",
    "# Explain the prediction\n",
    "explanation = explainer.explain_instance(\n",
    "    input_text,\n",
    "    model_wrapper.predict,  # Use batched prediction from ModelWrapper\n",
    "    num_features=5,         # Highlight fewer tokens\n",
    "    top_labels=1,           # Only explain the top predicted label\n",
    "    num_samples=500         # Reduced perturbation samples for efficiency\n",
    ")\n",
    "\n",
    "# Visualize explanation\n",
    "explanation.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sequence lengths to determine optimal max_len\n",
    "all_sequences = data['human'].apply(lambda x: word_tokenize(x.lower())) + data['gpt'].apply(lambda x: word_tokenize(x.lower()))\n",
    "sequence_lengths = all_sequences.apply(len)\n",
    "\n",
    "# Use 95th percentile for max_len\n",
    "import numpy as np\n",
    "max_len = int(np.percentile(sequence_lengths, 95))\n",
    "print(f\"Optimal max_len (95th percentile): {max_len}\")\n",
    "\n",
    "# Adjust batch size and tokenize\n",
    "batch_size = 16  # Adjusted for memory optimization\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on the combined text\n",
    "data_combined = data['human'] + \" \" + data['gpt']\n",
    "tokenizer.fit_on_texts(data_combined)\n",
    "\n",
    "# Convert texts to sequences and pad them to max_len\n",
    "sequences = tokenizer.texts_to_sequences(data_combined)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(\n",
    "    padded_sequences, np.zeros((len(padded_sequences), 1)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train data shape: {train_sequences.shape}\")\n",
    "print(f\"Test data shape: {test_sequences.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sequence lengths to determine optimal max_len\n",
    "all_sequences = data['human'].apply(lambda x: word_tokenize(x.lower())) + data['gpt'].apply(lambda x: word_tokenize(x.lower()))\n",
    "sequence_lengths = all_sequences.apply(len)\n",
    "\n",
    "# Use 95th percentile for max_len\n",
    "import numpy as np\n",
    "max_len = int(np.percentile(sequence_lengths, 95))\n",
    "print(f\"Optimal max_len (95th percentile): {max_len}\")\n",
    "\n",
    "# Adjust batch size and tokenize\n",
    "batch_size = 16  # Adjusted for memory optimization\n",
    "learning_rate = 0.001  # Fine-tuned learning rate\n",
    "embedding_dim = 128  # Fine-tuned embedding dimensions\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on the combined text\n",
    "data_combined = data['human'] + \" \" + data['gpt']\n",
    "tokenizer.fit_on_texts(data_combined)\n",
    "\n",
    "# Convert texts to sequences and pad them to max_len\n",
    "sequences = tokenizer.texts_to_sequences(data_combined)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(\n",
    "    padded_sequences, np.zeros((len(padded_sequences), 1)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train data shape: {train_sequences.shape}\")\n",
    "print(f\"Test data shape: {test_sequences.shape}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
